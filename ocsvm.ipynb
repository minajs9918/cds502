{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"One-class SVM detector. Implemented on scikit-learn library.\n", "\"\"\"\n", "# Author: Yue Zhao <zhaoy@cmu.edu>\n", "# License: BSD 2 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import division\n", "from __future__ import print_function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.svm import OneClassSVM\n", "from sklearn.utils.validation import check_is_fitted\n", "from sklearn.utils import check_array"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from .base import BaseDetector\n", "from ..utils.utility import invert_order"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class OCSVM(BaseDetector):\n", "    \"\"\"Wrapper of scikit-learn one-class SVM Class with more functionalities.\n", "    Unsupervised Outlier Detection.\n", "    Estimate the support of a high-dimensional distribution.\n", "    The implementation is based on libsvm.\n", "    See http://scikit-learn.org/stable/modules/svm.html#svm-outlier-detection\n", "    and :cite:`scholkopf2001estimating`.\n", "    Parameters\n", "    ----------\n", "    kernel : string, optional (default='rbf')\n", "         Specifies the kernel type to be used in the algorithm.\n", "         It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n", "         a callable.\n", "         If none is given, 'rbf' will be used. If a callable is given it is\n", "         used to precompute the kernel matrix.\n", "    nu : float, optional\n", "        An upper bound on the fraction of training\n", "        errors and a lower bound of the fraction of support\n", "        vectors. Should be in the interval (0, 1]. By default 0.5\n", "        will be taken.\n", "    degree : int, optional (default=3)\n", "        Degree of the polynomial kernel function ('poly').\n", "        Ignored by all other kernels.\n", "    gamma : float, optional (default='auto')\n", "        Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n", "        If gamma is 'auto' then 1/n_features will be used instead.\n", "    coef0 : float, optional (default=0.0)\n", "        Independent term in kernel function.\n", "        It is only significant in 'poly' and 'sigmoid'.\n", "    tol : float, optional\n", "        Tolerance for stopping criterion.\n", "    shrinking : bool, optional\n", "        Whether to use the shrinking heuristic.\n", "    cache_size : float, optional\n", "        Specify the size of the kernel cache (in MB).\n", "    verbose : bool, default: False\n", "        Enable verbose output. Note that this setting takes advantage of a\n", "        per-process runtime setting in libsvm that, if enabled, may not work\n", "        properly in a multithreaded context.\n", "    max_iter : int, optional (default=-1)\n", "        Hard limit on iterations within solver, or -1 for no limit.\n", "    contamination : float in (0., 0.5), optional (default=0.1)\n", "        The amount of contamination of the data set, i.e.\n", "        the proportion of outliers in the data set. Used when fitting to\n", "        define the threshold on the decision function."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    Attributes\n", "    ----------\n", "    support_ : array-like, shape = [n_SV]\n", "        Indices of support vectors.\n", "    support_vectors_ : array-like, shape = [nSV, n_features]\n", "        Support vectors.\n", "    dual_coef_ : array, shape = [1, n_SV]\n", "        Coefficients of the support vectors in the decision function.\n", "    coef_ : array, shape = [1, n_features]\n", "        Weights assigned to the features (coefficients in the primal\n", "        problem). This is only available in the case of a linear kernel.\n", "        `coef_` is readonly property derived from `dual_coef_` and\n", "        `support_vectors_`\n", "    intercept_ : array, shape = [1,]\n", "        Constant in the decision function.\n", "    decision_scores_ : numpy array of shape (n_samples,)\n", "        The outlier scores of the training data.\n", "        The higher, the more abnormal. Outliers tend to have higher\n", "        scores. This value is available once the detector is fitted.\n", "    threshold_ : float\n", "        The threshold is based on ``contamination``. It is the\n", "        ``n_samples * contamination`` most abnormal samples in\n", "        ``decision_scores_``. The threshold is calculated for generating\n", "        binary outlier labels.\n", "    labels_ : int, either 0 or 1\n", "        The binary labels of the training data. 0 stands for inliers\n", "        and 1 for outliers/anomalies. It is generated by applying\n", "        ``threshold_`` on ``decision_scores_``.\n", "    \"\"\"\n", "    def __init__(self, kernel='rbf', degree=3, gamma='auto', coef0=0.0,\n", "                 tol=1e-3, nu=0.5, shrinking=True, cache_size=200,\n", "                 verbose=False, max_iter=-1, contamination=0.1):\n", "        super(OCSVM, self).__init__(contamination=contamination)\n", "        self.kernel = kernel\n", "        self.degree = degree\n", "        self.gamma = gamma\n", "        self.coef0 = coef0\n", "        self.tol = tol\n", "        self.nu = nu\n", "        self.shrinking = shrinking\n", "        self.cache_size = cache_size\n", "        self.verbose = verbose\n", "        self.max_iter = max_iter\n", "    def fit(self, X, y=None, sample_weight=None, **params):\n", "        \"\"\"Fit detector. y is ignored in unsupervised methods.\n", "        Parameters\n", "        ----------\n", "        X : numpy array of shape (n_samples, n_features)\n", "            The input samples.\n", "        y : Ignored\n", "            Not used, present for API consistency by convention.\n", "        sample_weight : array-like, shape (n_samples,)\n", "            Per-sample weights. Rescale C per sample. Higher weights\n", "            force the classifier to put more emphasis on these points.\n", "        Returns\n", "        -------\n", "        self : object\n", "            Fitted estimator.\n", "        \"\"\"\n", "        # validate inputs X and y (optional)\n", "        X = check_array(X)\n", "        self._set_n_classes(y)\n", "        self.detector_ = OneClassSVM(kernel=self.kernel,\n", "                                     degree=self.degree,\n", "                                     gamma=self.gamma,\n", "                                     coef0=self.coef0,\n", "                                     tol=self.tol,\n", "                                     nu=self.nu,\n", "                                     shrinking=self.shrinking,\n", "                                     cache_size=self.cache_size,\n", "                                     verbose=self.verbose,\n", "                                     max_iter=self.max_iter)\n", "        self.detector_.fit(X=X, y=y, sample_weight=sample_weight,\n", "                           **params)\n\n", "        # invert decision_scores_. Outliers comes with higher outlier scores\n", "        self.decision_scores_ = invert_order(\n", "            self.detector_.decision_function(X))\n", "        self._process_decision_scores()\n", "        return self\n", "    def decision_function(self, X):\n", "        \"\"\"Predict raw anomaly score of X using the fitted detector.\n", "        The anomaly score of an input sample is computed based on different\n", "        detector algorithms. For consistency, outliers are assigned with\n", "        larger anomaly scores.\n", "        Parameters\n", "        ----------\n", "        X : numpy array of shape (n_samples, n_features)\n", "            The training input samples. Sparse matrices are accepted only\n", "            if they are supported by the base estimator.\n", "        Returns\n", "        -------\n", "        anomaly_scores : numpy array of shape (n_samples,)\n", "            The anomaly score of the input samples.\n", "        \"\"\"\n", "        check_is_fitted(self, ['decision_scores_', 'threshold_', 'labels_'])\n", "        # Invert outlier scores. Outliers comes with higher outlier scores\n", "        return invert_order(self.detector_.decision_function(X))\n", "    @property\n", "    def support_(self):\n", "        \"\"\"Indices of support vectors.\n", "        Decorator for scikit-learn One class SVM attributes.\n", "        \"\"\"\n", "        return self.detector_.support_\n", "    @property\n", "    def support_vectors_(self):\n", "        \"\"\"Support vectors.\n", "        Decorator for scikit-learn One class SVM attributes.\n", "        \"\"\"\n", "        return self.detector_.support_vectors_\n", "    @property\n", "    def dual_coef_(self):\n", "        \"\"\"Coefficients of the support vectors in the decision function.\n", "        Decorator for scikit-learn One class SVM attributes.\n", "        \"\"\"\n", "        return self.detector_.dual_coef_\n", "    @property\n", "    def coef_(self):\n", "        \"\"\"Weights assigned to the features (coefficients in the primal\n", "        problem). This is only available in the case of a linear kernel.\n", "        `coef_` is readonly property derived from `dual_coef_` and\n", "        `support_vectors_`\n", "        Decorator for scikit-learn One class SVM attributes.\n", "        \"\"\"\n", "        return self.detector_.coef_\n", "    @property\n", "    def intercept_(self):\n", "        \"\"\" Constant in the decision function.\n", "        Decorator for scikit-learn One class SVM attributes.\n", "        \"\"\"\n", "        return self.detector_.intercept_"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}